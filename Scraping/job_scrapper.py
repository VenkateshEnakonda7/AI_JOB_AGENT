import time
import re
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from utils.logger import log




def scrape_naukri_jobs(driver, sheet):
    driver.get("https://www.naukri.com/jobs-in-india")
    time.sleep(2)

    try:
        close_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, "//button[@class='close']"))
        )
        close_button.click()
    except Exception:
        log("No pop-up appeared.")

    # Search for the job
    driver.find_element(By.CLASS_NAME, "nI-gNb-sb__main").click()

    search_box = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.XPATH, "//*[@id='root']/div/div[3]/div[2]/div[1]/div/div/div[2]/div/div/div/input"))
    )
    search_box.send_keys("Automation Testing")
    search_box.send_keys(Keys.RETURN)
    time.sleep(5)

    n = 0
    while n <= 10:
        log(f"Scraping page {n}...")
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')

        job_cards = soup.find_all('div', class_='srp-jobtuple-wrapper')
        log(f"Number of job cards found: {len(job_cards)}")

        for job in job_cards:
            try:
                title = job.find('a', class_='title').text.strip()
                company = job.find('a', class_='comp-name mw-25').text.strip()
                experience = job.find('span', class_='expwdth').text.strip()
                salary = job.find('span', class_='ni-job-tuple-icon ni-job-tuple-icon-srp-rupee sal').text.strip()
                location = job.find('span', class_='locWdth').text.strip()
                posted_text = job.find('span', class_='job-post-day').text.strip()

                match = re.search(r'(\d+)\s+day', posted_text.lower())
                days_ago = int(match.group(1)) if match else 0
                posted_date = datetime.now() - timedelta(days=days_ago)
                posted_date_str = posted_date.strftime('%Y-%m-%d')

                link = job.find('a', class_='title').get('href')
            except Exception as e:
                log(f"Error extracting job details: {e}")
                continue

            # Open job link to extract description
            driver.execute_script("window.open(arguments[0], '_blank');", link)
            driver.switch_to.window(driver.window_handles[-1])
            time.sleep(2)

            try:
                job_description = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.XPATH, "//*[@id='root']/div/main/div[1]/div[1]/section[2]/div[3]"))
                ).text.strip()
            except Exception:
                job_description = "No description available"

            driver.close()
            driver.switch_to.window(driver.window_handles[0])

            # Save to sheet
            sheet.append_row([title, company, experience, salary, location, posted_date_str, link, job_description])
            log(f"âœ… Inserted: {title} - {company}")

        try:
            next_button = driver.find_element(By.XPATH, "//*[@id='lastCompMark']/a[2]")
            next_button.click()
            n += 1
            time.sleep(5)
        except Exception:
            log("No next button. Ending scraping.")
            break
